\documentclass{article}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm, algpseudocodex}
\usepackage{bm}
\usepackage{parskip}

\author{Xianghao Wang}
\title{Matrix Computations Exercise 1.2}
\begin{document}
\maketitle

\newcommand{\floor}[1]{\lfloor#1\rfloor}

\section*{Question 10}
\begin{align*}
    \bm{X}\bm{Y}^T & = (\bm{A}+\bm{u}\bm{v}^T)^k - \bm{A}^k                                                                 \\
                   & = \left[\sum_{r=0}^{k} \binom{k}{r} \bm{A}^{k-r} (\bm{u}\bm{v}^T)^r\right] - \bm{A}^k                  \\
                   & = \sum_{r=1}^k \binom{k}{r} \bm{A}^{k-r} (\bm{u}\bm{v}^T)^r                                            \\
                   & = \sum_{r=1}^k \left[\binom{k}{r} \bm{A}^{k-r}\bm{u}\right]\left[\bm{v}^T(\bm{u}\bm{v}^T)^{r-1}\right] \\
                   & =
    \begin{bmatrix}
        \binom{k}{1} \bm{A}^{k-1}\bm{u} &
        \binom{k}{2} \bm{A}^{k-2}\bm{u} &
        \dots                           &
        \binom{k}{k} \bm{A}^{k-k}\bm{u}
    \end{bmatrix}
    \begin{bmatrix}
        \bm{v}^T(\bm{u}\bm{v}^T)^0 \\
        \bm{v}^T(\bm{u}\bm{v}^T)^1 \\
        \vdots                     \\
        \bm{v}^T(\bm{u}\bm{v}^T)^{k-1}
    \end{bmatrix}
\end{align*}

Thus, we have:
\begin{equation*}
    \bm{X} =
    \begin{bmatrix}
        \binom{k}{1} \bm{A}^{k-1}\bm{u} &
        \binom{k}{2} \bm{A}^{k-2}\bm{u} &
        \dots                           &
        \binom{k}{k} \bm{A}^{k-k}\bm{u}
    \end{bmatrix}
\end{equation*}
\begin{equation*}
    \bm{Y} =
    \begin{bmatrix}
        (\bm{v}\bm{u}^T)^0\bm{v}  &
        (\bm{v}\bm{u}^T)^1 \bm{v} &
        \dots                     &
        (\bm{v}\bm{u}^T)^{k-1}\bm{v}
    \end{bmatrix}
\end{equation*}


We compute each column $j$ of $\bm{X}$ via the following algorithm.
It takes ${2(k-1)n^2+kn}$ flops.

\begin{algorithm}
    \begin{algorithmic}[1]
        \State $\bm{x} = \bm{u}$
        \For{$j=k:1$}
        \State $X(:,j) = \binom{k}{j}\bm{x}$ \Comment{$n$}

        \If{$j\neq 1$}
        \State $\bm{x} = \bm{A}\bm{x}$ \Comment{$2n^2$}
        \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}

To compute $\bm{Y}$, we rewrite each column $j$ to $\bm{v}(\bm{u}^T\bm{v})^{j-1}$ to get rid of matrix-vector multiplications.
It takes $2n+(k-1)n$ flops.

\begin{algorithm}[H]
    \begin{algorithmic}[1]
        \State $a=\bm{u}^T\bm{v}$ \Comment{$2n$}
        \State $\bm{y}=\bm{v}$
        \For{$j=1:k$}
        \State $Y(:,j) = \bm{y}$
        \If{$j\neq 1$}
        \State $\bm{y}=a\bm{y}$ \Comment{$n$}
        \EndIf
        \EndFor
    \end{algorithmic}
\end{algorithm}

In total, computing $\bm{X}$ and $\bm{Y}$ takes approximate $2kn^2$ flops.

\section*{Question 12}
\textbf{Note:} We use $0$-based indexing for simplification.

Suppose row $i$ of $\mathcal{P}_{pr}$ is row $j$ of the identity matrix $\bm{I}_n$.
Let $j$ be the $t_{ip}$\textsuperscript{th} element of the $s_{ip}$\textsuperscript{th} pile, where
$t_{ip}, s_{ip}$ are associated with $i$. Then, we have the following:
\begin{align*}
    \mathcal{P}_{pr}(i,j) & =
    \begin{cases}
        1 & j =  t_{ip}r+s_{ip} \\
        0 & \text{otherwise}
    \end{cases}                       \\
    \intertext{where}
    t_{ip}                & = i \bmod p           \\
    s_{ip}                & = \floor{\frac{i}{p}}
\end{align*}

We focus on the condition $j = t_{ip}r+s_{ip}$.
\begin{align*}
             & j = s_{ip}r+t_{ip}                                                                                     \\
    \implies & s_{jr}r+t_{jr} = t_{ip}r+s_{ip}                                                                        \\
    \implies & s_{jr}n+t_{jr}p = t_{ip}n+s_{ip}p \tag*{$r=\frac{n}{p}$}                                               \\
    \implies & t_{jr}p + s_{jr} + s_{jr}(n-1) = i + t_{ip}(n-1) \tag*{$i=s_{ip}p+t_{ip}$}                             \\
    \implies & t_{jr}p + s_{jr} + \floor{\frac{j}{r}}(n-1) = i + t_{ip}(n-1)                                          \\
    \implies & t_{jr}p + s_{jr} + \floor{\frac{t_{ip}r+s_{ip}}{r}}(n-1) = i + t_{ip}(n-1) \tag*{$j = t_{ip}r+s_{ip}$} \\
    \implies & t_{jr}p + s_{jr} + t_{ip}(n-1) = i+t_{ip}(n-1) \tag*{$s_{ip}=\floor{\frac{i}{p}},i<pr$}                \\
    \implies & i = t_{jr}p + s_{jr}
\end{align*}

This means $\mathcal{P}_{pr}(i,j)=\mathcal{P}_{rp}(j,i)$. Thus, we have $\mathcal{P}_{pr}=\mathcal{P}^T_{rp}$ i.e. $\mathcal{P}^T_{pr}=\mathcal{P}_{rp}$.

\section*{Question 13}
There are $2$ symmetric permutation matrices for $n>1$, which are $\bm{I}_n$ and $\bm{I}_n(n:-1:1,:)$.

\end{document}